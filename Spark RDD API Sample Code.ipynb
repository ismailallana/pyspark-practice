{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "spark_conf = SparkConf()\\\n",
    "        .setAppName(\"Week 5 Lecture Sample Code\")\n",
    "sc=SparkContext.getOrCreate(spark_conf) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count Program ###\n",
    "\n",
    "This is the word count program used in week 5 lecture to illustrate basic spark program structure. It reads a text file from local disk and count the occurance of words in the text. For simplicity, words are considered as separaetd by white space only.\n",
    "\n",
    "**Each run of this cell will create an output directory called 1984_wordcount. To re-run the cell, you need to remove that directory**\n",
    "\n",
    "You can access the terminal to remove the output directory, or expend the \"Files\" tab on the left verticle bar to get the file panel and delete from there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '1984-GeorgeOrwell.txt'\n",
    "output_path = '1984_wordcount'\n",
    "\n",
    "text_file = sc.textFile(input_file)\n",
    "\n",
    "### FILE ###\n",
    "# Alice and Bob are playing in the field\n",
    "# Jack and Jill are running up the hill\n",
    "############\n",
    "\n",
    "# map --> [[\"Alice\", \"and\", \"Bob\", \"are\", \"playing\", \"in\", \"the\", \"field\"], [\"Jack\", \"and\", \"Jill\", ...]]\n",
    "# flatMap --> [\"Alice\", \"and\", \"Bob\", \"are\", \"playing\", \"in\", \"the\", \"field\", \"Jack\", \"and\", \"Jill\", ...]\n",
    "\n",
    "\n",
    "counts = text_file.flatMap(lambda line: line.strip().split(\" \")).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "counts.saveAsTextFile(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map style transformations\n",
    "\n",
    " `map` vs. `mapValues`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [('a',1),('b',2),('c',3),('d',4),('e',5)]\n",
    "distRDD = sc.parallelize(d)\n",
    "\n",
    "#convert to kms\n",
    "kvmap= distRDD.map(lambda rec: (rec[0],rec[1] * 1.6)).collect()\n",
    "kvmapvalues = distRDD.mapValues(lambda dist: dist * 1.6).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 1.6), ('b', 3.2), ('c', 4.800000000000001), ('d', 6.4), ('e', 8.0)]\n",
      "[('a', 1.6), ('b', 3.2), ('c', 4.800000000000001), ('d', 6.4), ('e', 8.0)]\n"
     ]
    }
   ],
   "source": [
    "print(kvmap)\n",
    "print(kvmapvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map style transformation \n",
    "\n",
    "`filter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', 3), ('d', 4), ('e', 5)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longDist = distRDD.filter(lambda rec: rec[1] > 2)\n",
    "longDist.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Rating Computing ###\n",
    "\n",
    "This is a sample notebook showing basic spark RDD operations. The program has two input data sources: *ratings.csv* and *movies.csv*.\n",
    "\n",
    "The *movies.csv* file contains movie information. Each row represents one movie, and has the following format:\n",
    "\n",
    "`movieId,title,genres`\n",
    "\n",
    "The *ratings.csv* file contains rating information. Each row represents one rating of one movie by one user, and has the following format:\n",
    "\n",
    "`userId,movieId,rating,timestamp`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following cell defines a number of functions to be used in the computation ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\"\"\"\n",
    "This module includes a few functions used in computing average rating per genre\n",
    "\"\"\"\n",
    "def pairMovieToGenre(record):\n",
    "    \"\"\"This function converts entries of movies.csv into key,value pair of the following format\n",
    "    (movieID, genre)\n",
    "    since there may be multiple genre per movie, this function returns a list of tuples\n",
    "    Args:\n",
    "        record (str): A row of CSV file, with three columns separated by comma\n",
    "    Returns:\n",
    "        The return value is a list of tuples, each tuple contains (movieID, genre)\n",
    "    \"\"\"\n",
    "    for row in csv.reader([record]):\n",
    "        if len(row) != 3:\n",
    "            continue\n",
    "        movieID, genreList = row[0],row[2]\n",
    "        return [(movieID, genre) for genre in genreList.split(\"|\")]\n",
    "\n",
    "def extractRating(record):\n",
    "    \"\"\" This function converts entries of ratings.csv into key,value pair of the following format\n",
    "    (movieID, rating)\n",
    "    Args:\n",
    "        record (str): A row of CSV file, with four columns separated by comma\n",
    "    Returns:\n",
    "        The return value is a tuple (movieID, genre)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        userID, movieID, rating, timestamp = record.split(\",\")\n",
    "        rating = float(rating)\n",
    "        return (movieID, rating)\n",
    "    except:\n",
    "        return ()\n",
    "\n",
    "def mapToPair(line):\n",
    "    \"\"\" This function converts tuples of (genre, rating) into key,value pair of the following format\n",
    "    (genre,rating)\n",
    "    \n",
    "    Args:\n",
    "        line (str): A touple of  (genre, rating) \n",
    "    Returns:\n",
    "        The return value is a tuple  (genre, rating) \n",
    "    \"\"\"\n",
    "    genre, rating = line\n",
    "    return (genre, rating)\n",
    "\n",
    "def avg(values):\n",
    "    #convert the iterable into a list\n",
    "    vlist = list(values) \n",
    "    # the average is the sum of the list divided by the count of the the list\n",
    "    return sum(vlist)/len(vlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This cell defines the spark function  skeleton (e.g. the computation graph ####\n",
    "\n",
    "To facilitate inspection of each intermediate RDD, we write each transformation in a separate statement. This is not necessary in production code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Drama', 3.6502661839863713),\n",
       " ('Romance', 3.544254739708809),\n",
       " ('Thriller', 3.4955613220431574),\n",
       " ('Sci-Fi', 3.4544805001488537),\n",
       " ('Fantasy', 3.5004591789879695),\n",
       " ('Musical', 3.57196174480989),\n",
       " ('Western', 3.565687121866897),\n",
       " ('Comedy', 3.4209959269478385),\n",
       " ('Adventure', 3.518027387762177),\n",
       " ('War', 3.7832017844886754),\n",
       " ('Film-Noir', 3.9136363636363636),\n",
       " ('Action', 3.4514500881269026),\n",
       " ('Horror', 3.281097331830139),\n",
       " ('Children', 3.4394294887626575),\n",
       " ('Documentary', 3.6430348258706466),\n",
       " ('IMAX', 3.641820580474934),\n",
       " ('Crime', 3.6423924334372098),\n",
       " ('Mystery', 3.652043269230769),\n",
       " ('Animation', 3.6353503184713376),\n",
       " ('(no genres listed)', 3.0714285714285716)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = 'ratingOut'\n",
    "\n",
    "#read the input as line and convert into RDD of String\n",
    "ratingData = sc.textFile(\"ratings.csv\")\n",
    "movieData = sc.textFile(\"movies.csv\")\n",
    "\n",
    "movieRatings = ratingData.map(extractRating)\n",
    "# we use flatMap as there are multiple genre per movie\n",
    "movieGenre = movieData.flatMap(pairMovieToGenre)\n",
    "\n",
    "# join  the two RDDs\n",
    "joined = movieGenre.join(movieRatings)\n",
    "# throw away the movieID which is useless for subsequent computation\n",
    "joined_gk = joined.values()\n",
    "# group ratings by genre\n",
    "grouped = joined_gk.groupByKey()\n",
    "genreRatingsAvg = grouped.mapValues(avg).collect()\n",
    "\n",
    "''' The short hand version\n",
    "genreRatingsAvg = movieGenre \\\n",
    "    .join(movieRatings) \\\n",
    "    .values() \\\n",
    "    .groupByKey() \\\n",
    "    .mapValues(avg) \\\n",
    "    .collect()\n",
    "'''\n",
    "genreRatingsAvg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check RDD element ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy',\n",
       " '2,Jumanji (1995),Adventure|Children|Fantasy']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What does movieData look like\n",
    "#Each row is a string\n",
    "movieData.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('16', 4.0), ('24', 1.5)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does movieRatings RDD look like\n",
    "# Each row is a tuple of String, float\n",
    "movieRatings.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movieRatings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-004ccda7fecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#How many element are there in movieRatings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmovieRatings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'movieRatings' is not defined"
     ]
    }
   ],
   "source": [
    "#How many element are there in movieRatings\n",
    "movieRatings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'Adventure'), ('1', 'Animation')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what does moveGenre RDD look like\n",
    "#Each row is a tuple of string, string\n",
    "movieGenre.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23114"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many element are there in movieGenre\n",
    "movieGenre.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4', ('Comedy', 3.5)), ('4', ('Comedy', 3.0))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what does joined look like \n",
    "# we are joinning (mid, genre) with (mid, rating)\n",
    "# the result is (mid, (genre, rating))\n",
    "joined.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Comedy', 3.5), ('Comedy', 3.0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does joined_gk look like\n",
    "# a touple of (string, float) representing (genre, rating)\n",
    "joined_gk.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Drama', <pyspark.resultiterable.ResultIterable at 0x7f19b2ada8d0>),\n",
       " ('Romance', <pyspark.resultiterable.ResultIterable at 0x7f19b2ada190>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When we run groupByKey on joined_gk, all rating values \n",
    "# for the same genre will be grouped into a single sequence as an iterable object\n",
    "grouped.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['126929', '135460', '138863', '141305', '141472', '143709', '149532']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieData = sc.textFile(\"movies.csv\")\n",
    "movieData.filter(lambda line: '(no genres listed)' in line) \\\n",
    "         .map(lambda row: row.split(\",\")[0]) \\\n",
    "         .collect() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "docMovie = movieData.filter(lambda row: 'Documentary' in row) \\\n",
    "    .map(lambda row: (row.split(\",\")[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieRatings = sc.textFile(\"ratings.csv\") \\\n",
    "                .map(extractRating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5669', 51), ('246', 36), ('2064', 35), ('8464', 33), ('8622', 33)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_rating = docMovie.join(movieRatings)\n",
    "\n",
    "doc_rating.reduceByKey(lambda v1,v2: (v1[0]+v2[0], 0)) \\\n",
    "        .mapValues(lambda v: v[0]) \\\n",
    "        .sortBy(lambda r:r[1],ascending=False) \\\n",
    "        .take(5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\"\"\"\n",
    "This module includes a few functions used in computing average rating per genre\n",
    "\"\"\"\n",
    "def getGenrePairs(record):\n",
    "    \"\"\"This function converts entries of movies.csv into ((g1,g2),1) pair for all genres \n",
    "    appearing in the row. \n",
    "    since there may be multiple genre per movie, this function returns a list of tuples\n",
    "    Args:\n",
    "        record (str): A row of CSV file, with three columns separated by comma\n",
    "    Returns:\n",
    "        The return value is a list of tuples, each tuple contains ((g1,g2), 1)\n",
    "    \"\"\"\n",
    "    for row in csv.reader([record]):\n",
    "        if len(row) != 3:\n",
    "            return []\n",
    "        genre_list = row[2].split(\"|\")\n",
    "        g = len(genre_list)\n",
    "        if g<2 : #single genre case\n",
    "            return []\n",
    "        # at least two genre case\n",
    "        results = []\n",
    "        sorted_glist = sorted(genre_list) # sort by aphabet order\n",
    "\n",
    "        for i in range(g): \n",
    "            for j in range(i+1,g): # from 1 to last\n",
    "                results.append(((sorted_glist[i],sorted_glist[j]),1))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Drama', 'Romance'), 1096),\n",
       " (('Comedy', 'Drama'), 1039),\n",
       " (('Drama', 'Thriller'), 1016),\n",
       " (('Comedy', 'Romance'), 892),\n",
       " (('Crime', 'Drama'), 841)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieData.flatMap(getGenrePairs)\\\n",
    "    .reduceByKey(lambda a,b:a+b) \\\n",
    "    .sortBy(lambda r: r[1],ascending=False).take(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
